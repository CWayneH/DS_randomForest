library(ggvis)
library(ggbiplot)
data(iris)
iris <- iris[, -5]
names(iris) <- c("PC1", "PC2", "PC3", "PC4")
# apply ca
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
head(ca1$rowcoord)
head(ca1$colcoord)
plot(cal)
# CA with function ca
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
data(iris)
iris <- iris[, -5]
# apply ca
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
head(ca1$rowcoord)
head(ca1$colcoord)
plot(cal)
# CA with function ca
library(ca)
# apply ca
ca1 = ca(author)
# sqrt of eigenvalues
ca1$sv
plot(cal)
# CA with function ca
library(ca)
# apply ca
ca1 = ca(author)
# sqrt of eigenvalues
ca1$sv
head(ca1$rowcoord)
head(ca1$colcoord)
plot(cal)
# CA with function ca
library(ca)
# apply ca
ca1 <- ca(author)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
# CA with function ca
library(ca)
library(shiny)
# apply ca
ca1 <- ca(author)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
# CA with function ca
library(ca)
library(shiny)
library(ggvis)
# apply ca
ca1 <- ca(author)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
# CA with function ca
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
# apply ca
ca1 <- ca(author)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
# CA with function ca
library(ca)
# CA with function ca
# CA with function ca
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
data(iris)
iris <- iris[, -5]
# apply ca
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
head(ca1$rowcoord)
head(ca1$colcoord)
plot(cal)
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
# apply ca
ca1 <- ca(author)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
# CA with function ca
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
data(iris)
iris <- iris[, -5]
# apply ca
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
head(ca1$rowcoord)
head(ca1$colcoord)
plot(cal)
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
# apply ca
data(iris)
iris <- iris[, -5]
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
# CA with function ca
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
data(iris)
iris <- iris[, -5]
# apply ca
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
head(ca1$rowcoord)
head(ca1$colcoord)
plot(cal)
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
# apply ca
data(iris)
iris <- iris[, -5]
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
library(ca)
library(shiny)
library(ggvis)
library(ggbiplot)
# apply ca
data(iris)
iris <- iris[, -5]
names(iris) <- c("PC1", "PC2", "PC3", "PC4")
ca1 <- ca(iris)
# sqrt of eigenvalues
ca1$sv
# row coordinates
head(ca1$rowcoord)
# column coordinates
head(ca1$colcoord)
plot(ca1)
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp()
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp()
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/CA')
runApp('hw4-kebwlmbhee/hw4')
runApp()
runApp('hw4-kebwlmbhee/hw4')
runApp()
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp()
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
library(shiny)
library(ggvis)
library(ggbiplot)
data(iris)
# log transform
log.ir <- log(iris[, 1:4])
ir.species <- iris[, 5]
# apply PCA - scale. = TRUE is highly advisable, but default is FALSE.
ir.pca <- prcomp(log.ir,center = TRUE, scale. = TRUE)
g <- ggbiplot(ir.pca, obs.scale = 1, var.scale = 1, groups = ir.species)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', legend.position = 'top')
PoV <- ir.pca$sdev^2/sum(ir.pca$sdev^2)
PoV
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
library(shiny)
library(ggvis)
library(ggbiplot)
data(iris)
# log transform
log.ir <- log(iris[, 1:4])
ir.species <- iris[, 5]
# apply PCA - scale. = TRUE is highly advisable, but default is FALSE.
ir.pca <- prcomp(log.ir,center = TRUE, scale. = TRUE)
g <- ggbiplot(ir.pca, obs.scale = 1, var.scale = 1, groups = ir.species)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', legend.position = 'top')
PoV <- ir.pca$sdev^2/sum(ir.pca$sdev^2)
PoV
summary(pc)$importance[2,]
summary(ir.pca)$importance[2,]
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
?column
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/hw4')
runApp()
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
summary(ir.pca)$importance[2,]
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/test')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
runApp('hw4-kebwlmbhee/hw4')
install.packages('randomForest')
?randomForest
setwd("D:/OneDrive - nccu.edu.tw/Data_Science/HW/ds_final")
rm(list = ls())
library('randomForest')
library('ggplot2')
train_data <- read.csv(file = "train_salary.csv", header = T, stringAsFactors = F)
train_data <- read.csv(file = train_salary.csv, header = T, stringAsFactors = F)
setwd("D:/OneDrive - nccu.edu.tw/Data_Science/HW/ds_final")
read.csv(file = train_salary.csv, header = T, stringAsFactors = F)
train_data <- read.csv(file = 'train_salary.csv', header = T, stringAsFactors = F)
train_data <- read.csv(file = "train_salary.csv", header = T, stringAsFactors = F)
setwd("D:/OneDrive - nccu.edu.tw/Data_Science/HW")
train_data <- read.csv(file = "ds_final/train_salary.csv", header = T, stringAsFactors = F)
q()
fold <- 5
train_data <- read.csv(file = "ds_final/train_salary.csv", header = T, stringsAsFactors = F)
test_data <- read.csv(file = "ds_final/test_salary.csv", header = T, stringsAsFactors = F)
# ================== add IsTrain for merge two dataset ===================
train_data$IsTrain <- TRUE
test_data$IsTrain <- FALSE
# ================================ merge =================================
merge <- rbind(train_data, test_data)
# ============================ rename feature ============================
merge <- merge[-1]
colnames(merge) <- c("x1", "x2", "x3", "x4", "x5",
"x6", "x7", "x8", "y", "x10",
"x11", "x12", "x13", "x14", "x15",
"x16", "x17", "x18", "x19", "x20",
"x21", "x22", "x23", "x24", "x25",
"x26", "x27", "x28", "IsTrain")
# = deal with NA and NULL value, let them be median(num) and mode(char) =
merge[is.na(merge$x26), "x26"] <- median(merge$x26, na.rm = T)
# ====================== split into train and test ======================
train_data <- merge[merge$IsTrain == T, ]
test_data <- merge[merge$IsTrain == F, ]
# =============== boxplot(round(train_data$x4/50000, 0)) ================
train_data$x4 <- round(train_data$x4 / 50000, 0)
train_data <- subset(train_data,
train_data$x4 <= 16)
# ================ boxplot(round(train_data$x6 / 4, 0)) =================
train_data$x6 <- round(train_data$x6 / 4, 0)
train_data <- subset(train_data,
train_data$x6 <= 6)
boxplot(round(train_data$x7 / 4, 0))
train_data$x7 <- round(train_data$x7 / 4, 0)
train_data <- subset(train_data,
train_data$x7 <= 6)
train_data$x10 <- round(train_data$x10 / 10000, 0)
train_data$x10 <- round(train_data$x10, 0)
train_data <- subset(train_data,
train_data$x10 <= 20)
train_data$x11 <- round(train_data$x11 / 10000, 0)
train_data$x11 <- round(train_data$x11, 0)
train_data <- subset(train_data,
train_data$x11 <= 20)
# ==================== convert char feature to factor ====================
train_data[sapply(train_data, is.character)] <- lapply(train_data
[sapply(train_data,
is.character)],
as.factor)
# ========================= transfer to formula ==========================
interest <- as.formula(y ~ x4 + x6 + x7)
# =========================== add ID into data ===========================
ID <- c(1:nrow(train_data))
data <- cbind(ID, train_data)
# ============================== fold times ==============================
k <- as.numeric(fold)
# ========================== random id for split =========================
set.seed(1234)
data$gp <- runif(dim(data)[1])
split_train <- 0.6
split_test <- 0.2 + split_train
# ============================= null vector ==============================
set <- c()
training <- c()
validation <- c()
test <- c()
# ============================= null vector ==============================
RMSE <- c()
training <- c()
validation <- c()
test <- c()
# ======================= k-fold cross validation ========================
for(i in 1 : k){
# ========= select and split train_data, test_data, valid_data =========
train_d <- subset(data, data$gp <= split_train)   # <= 0.6
test_d <- subset(data, data$gp > split_train)     # > 0.6
test_d <- subset(test_d, test_d$gp <= split_test)    # > 0.6, <= 0.8
valid_d <- subset(data, data$gp > split_train)
# ================= set random seed to reproduce model =================
set.seed(4312)
# ========================== construct model ===========================
model <- randomForest(formula = interest, data = train_data, ntree = 50)
# =============== predict using model applied to train_d ===============
pred_train <- predict(model, newdata = train_d,
data.frame(Level = 6.5), type = "response")
result_train <- data.frame(ID = train_d$ID,
Base_salary = train_d$y,
predictions = pred_train)
result_train <- round(result_train, 4)
# print(paste('Train RMSE: ' , rmse(result_train$Base_salary,
#                                   result_train$predictions) )) #testRMSE
# =============== predict using model applied to test_d ===============
pred_test <- predict(model, newdata = test_d,
data.frame(Level = 6.5), type = "response")
result_test <- data.frame(ID = test_d$ID,
Base_salary = test_d$y,
predictions = pred_test)
result_test <- round(result_test, 4)
# print(paste('Test RMSE: ' , rmse(result_test$Base_salary,
#                             result_test$predictions) )) #testRMSE
# =============== predict using model applied to valid_d ==============
pred_valid <- predict(model, newdata = valid_d,
data.frame(Level = 6.5), type = "response")
result_valid <- data.frame(ID = valid_d$ID,
Base_salary = valid_d$y,
predictions = pred_valid)
result_valid <- round(result_valid, 4)
RMSE <- rmse(result_valid$Base_salary,result_valid$predictions) #testRMSE
# cuz test, validation, train data must right shift => d$gp right shift
data$gp <- (data$gp + (1/k)) %% 1
# =========================== add to vector ============================
RMSE <- c(RMSE, paste("fold", i, sep = ""))
training <- c(training, result_train)
test <- c(test, result_test)
validation <- c(validation, result_valid)
}
library(randomForest)
# ========= select and split train_data, test_data, valid_data =========
train_d <- subset(data, data$gp <= split_train)   # <= 0.6
test_d <- subset(data, data$gp > split_train)     # > 0.6
test_d <- subset(test_d, test_d$gp <= split_test)    # > 0.6, <= 0.8
valid_d <- subset(data, data$gp > split_train)
# ================= set random seed to reproduce model =================
set.seed(4312)
# ========================== construct model ===========================
model <- randomForest(formula = interest, data = train_data, ntree = 50)
# =============== predict using model applied to train_d ===============
pred_train <- predict(model, newdata = train_d,
data.frame(Level = 6.5), type = "response")
result_train <- data.frame(ID = train_d$ID,
Base_salary = train_d$y,
predictions = pred_train)
result_train <- round(result_train, 4)
# =============== predict using model applied to test_d ===============
pred_test <- predict(model, newdata = test_d,
data.frame(Level = 6.5), type = "response")
result_test <- data.frame(ID = test_d$ID,
Base_salary = test_d$y,
predictions = pred_test)
result_test <- round(result_test, 4)
# =============== predict using model applied to valid_d ==============
pred_valid <- predict(model, newdata = valid_d,
data.frame(Level = 6.5), type = "response")
result_valid <- data.frame(ID = valid_d$ID,
Base_salary = valid_d$y,
predictions = pred_valid)
result_valid <- round(result_valid, 4)
View(result_valid)
# ========= select and split train_data, test_data, valid_data =========
train_d <- subset(data, data$gp <= split_train)   # <= 0.6
test_d <- subset(data, data$gp > split_train)     # > 0.6
test_d <- subset(test_d, test_d$gp <= split_test)    # > 0.6, <= 0.8
valid_d <- subset(data, data$gp > split_train)
# ================= set random seed to reproduce model =================
set.seed(4312)
# ========================== construct model ===========================
model <- randomForest(formula = interest, data = train_data, ntree = 50)
# =============== predict using model applied to train_d ===============
pred_train <- predict(model, newdata = train_d,
data.frame(Level = 6.5), type = "response")
result_train <- round(rmse(result_train$Base_salary,
result_train$predictions)
, 4)
library(Metrics)
result_train <- round(rmse(result_train$Base_salary,
result_train$predictions)
, 4)
result_train
train_data$x10
unique(train_data$x10)
unique(train_data$x11)
unique(train_data$x7)
View(data)
View(merge)
View(merge)
View(merge)
unique(train_data$x3)
unique(train_data$x2)
unique(train_data$x1)
unique(train_data$x5)
unique(train_data$x8)
unique(train_data$x9)
unique(train_data$x12)
unique(train_data$x13)
unique(train_data$x14)
unique(train_data$x15)
unique(train_data$x16)
unique(train_data$x17)
