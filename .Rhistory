setwd("D:/OneDrive - nccu.edu.tw/Data_Science/HW/DS_randomForest")
library(randomForest)
library(ggplot2)
library(caret)
library(ggpubr)
library(Metrics)
train_input <- "ds_final/train_salary.csv"
test_input <- "ds_final/test_salary.csv"
# read train_input & test_input
train_data <- read.csv(file = train_input, header = T, stringsAsFactors = F)
test_data <- read.csv(file = test_input, header = T, stringsAsFactors = F)
# ================== add IsTrain for merge two dataset ===================
train_data$IsTrain <- TRUE
test_data$IsTrain <- FALSE
# ================================ merge =================================
merge <- rbind(train_data, test_data)
# ============================ rename feature ============================
merge <- merge[-1]
colnames(merge) <- c("x1", "x2", "x3", "x4", "x5",
"x6", "x7", "x8", "y", "x10",
"x11", "x12", "x13", "x14", "x15",
"x16", "x17", "x18", "x19", "x20",
"x21", "x22", "x23", "x24", "x25",
"x26", "x27", "x28", "IsTrain")
# = deal with NA and NULL value, let them be median(num) and mode(char) =
merge[is.na(merge$x26), "x26"] <- median(merge$x26, na.rm = T)
# ====================== split into train and test ======================
train_data <- merge[merge$IsTrain == T, ]
test_data <- merge[merge$IsTrain == F, ]
# ==================== convert char feature to factor ====================
train_data[sapply(train_data, is.character)] <- lapply(train_data
[sapply(train_data,
is.character)],
as.factor)
library(ggpubr)
# ================ analysis data through visualization =================
ggscatter(train_data, x = "x4", y = "y",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "x4", ylab = "salary")
shapiro.test(my_data$y)
shapiro.test(train_data$y)
# ========================= transfer to formula ==========================
interest <- as.formula(y ~ x4 + x6 + x7 + x10 + x11)
# =========================== add ID into data ===========================
ID <- c(1:nrow(train_data))
data <- cbind(ID, train_data)
# ============================== fold times ==============================
k <- as.numeric(fold)
# ========================== random id for split =========================
set.seed(1234)
data$gp <- runif(dim(data)[1])
split_train <- 0.6
split_test <- 0.2 + split_train
# ============================= null vector ==============================
set <- c()
training <- c()
validation <- c()
test <- c()
# ========= select and split train_data, test_data, valid_data =========
train_d <- subset(data, data$gp <= split_train)   # <= 0.6
test_d <- subset(data, data$gp > split_train)     # > 0.6
test_d <- subset(test_d, test_d$gp <= split_test)    # > 0.6, <= 0.8
valid_d <- subset(data, data$gp > split_train)
# ================= set random seed to reproduce model =================
set.seed(4312)
# ========================== construct model ===========================
model <- randomForest(formula = interest, data = train_data, ntree = 50,
importance = T)
importance(model)
plot(importance)
fit <- train(formula = interest, data = train_data, method = "rf")
fit <- train(formula = interest, data = na.omit(train_data), method = "rf")
memory.limit(50000)
fit <- train(formula = interest, data = na.omit(train_data), method = "rf")
